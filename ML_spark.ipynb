{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "authorship_tag": "ABX9TyPM84I5RsarN1k+ncBRlwl6",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/eji58/ML_spark/blob/main/ML_spark.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "install packeg of spark"
      ],
      "metadata": {
        "id": "Xyo6McD9n8-G"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pyspark"
      ],
      "metadata": {
        "id": "5-6ukHRomU5n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Importing Libraries\n"
      ],
      "metadata": {
        "id": "bRgHplnsn394"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uN1xRxBw18QE"
      },
      "outputs": [],
      "source": [
        "import numpy as np \n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt \n",
        "import pyspark\n",
        "\n",
        "from pyspark.sql.types import *\n",
        "from pyspark.sql.functions import *\n",
        "from pyspark.sql import SparkSession\n",
        "\n",
        "from pyspark.ml import Pipeline\n",
        "#from pyspark.ml.classification import DecisionTreeClassifier\n",
        "from pyspark.ml.feature import VectorAssembler, StringIndexer, VectorIndexer, MinMaxScaler\n",
        "from pyspark.ml.classification import LogisticRegression\n",
        "from pyspark.ml.tuning import ParamGridBuilder, CrossValidator\n",
        "from pyspark.ml.evaluation import BinaryClassificationEvaluator\n",
        "from pyspark.ml.evaluation import RegressionEvaluator\n",
        "from pyspark.ml.tuning import ParamGridBuilder, CrossValidator\n",
        "from pyspark.ml.feature import VectorAssembler\n",
        "from pyspark.ml.regression import LinearRegression\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Create Spark Session"
      ],
      "metadata": {
        "id": "RTOs-QjtoERi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "spark = SparkSession.builder.getOrCreate()"
      ],
      "metadata": {
        "id": "qO-S8BgGoJw-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "laod data"
      ],
      "metadata": {
        "id": "UP7WRgmeoBfJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df1=pd.read_csv(\"/content/amazon_co-ecommerce_sample.csv\",engine='python', error_bad_lines=False) \n",
        "df1"
      ],
      "metadata": {
        "id": "VzwbQIWpBmu3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fullpath='/content/amazon_co-ecommerce_sample.csv'"
      ],
      "metadata": {
        "id": "nZoFi8slnp_X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        " # general description of the dataset\n",
        " df = spark.read.csv(fullpath, sep=',', inferSchema=True, header=True)"
      ],
      "metadata": {
        "id": "BsRpf9tJniiv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Shape of the dataset\n",
        "print(‘Shape of the dataset: ‘, (df.count(), len(df.columns)))\n",
        "# Displaying top n=10 rows\n",
        "df.show(n=10)"
      ],
      "metadata": {
        "id": "9zww7IFmhNWJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.show(n=10)\n"
      ],
      "metadata": {
        "id": "YnPVH-jvqvpe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Preprocessing"
      ],
      "metadata": {
        "id": "dsEDFa18qJMo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df.describe().show()"
      ],
      "metadata": {
        "id": "cc-OOiaMhV6g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cols = df.columns\n",
        "# cols.remove('price') #our label\n",
        "# assembler = VectorAssembler(inputCols=data.cols, outputCol='features')\n",
        "# data = assembler.transform(data)\n",
        "# df_data = data.select(F.col('features'), F.col('price').alias('label'))"
      ],
      "metadata": {
        "id": "61pG5Ny4pjW3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cols"
      ],
      "metadata": {
        "id": "D6VL6qJZDSV7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Splitting the Dataset into Training and Testing Sets"
      ],
      "metadata": {
        "id": "AU0zeDsZqanY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_train, df_test = df_data.randomSplit([0.8, 0.2]) #only train and test\n",
        "df_train, df_hold, df_test = df_data.randomSplit([0.6, 0.2, 0.2]) #train, holdout, and test\n",
        "#alternatively, you can also set the random state by setting a number for seed\n",
        "df_train, df_test = df_data.randomSplit([0.8, 0.2], seed=24)"
      ],
      "metadata": {
        "id": "dV2OKIFspf8p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Evaluators and Grid\n",
        "\n"
      ],
      "metadata": {
        "id": "dwaaJPspqgfy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "evaluator = RegressionEvaluator()\n",
        "grid = ParamGridBuilder().build()"
      ],
      "metadata": {
        "id": "qJI5pSFKpW5l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Building a Model\n"
      ],
      "metadata": {
        "id": "q3SEmXNsqzGj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "classifier_lr = LinearRegression(maxIter=10, regParam=0.3, elasticNetParam=0.8 #adjust as you like\n",
        "cv_lr = CrossValidator(estimator=classifier_lr, evaluator=evaluator, estimatorParamMaps=grid, numFolds=5)\n",
        "cv_model_lr = cv_lr.fit(df_train)\n",
        "RegressionEvaluator(predictionCol='prediction', labelCol='label', metricName='mae') #r2, rmse, mae\n",
        ".evaluate(model.bestModel.transform(df_test))"
      ],
      "metadata": {
        "id": "zt4qAy6OqyUj"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}